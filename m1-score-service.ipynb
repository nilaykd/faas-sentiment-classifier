{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nilaykd/faas-sentiment-classifier/blob/main/m1-score-service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "zJb1Jv2YY6GY"
      },
      "outputs": [],
      "source": [
        "from nltk import download\n",
        "\n",
        "download('movie_reviews')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzzZXTZDY6Ga"
      },
      "source": [
        "### Load the data\n",
        "\n",
        "The files in movie_reviews have already been divided into two sets: positive ('pos') and negative ('neg'), so we can load the raw text of the reviews into two lists, one for each polarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj2nPQhKY6Gb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "# extract words from reviews, pair with label\n",
        "\n",
        "reviews_pos = []\n",
        "for fileid in movie_reviews.fileids('pos'):\n",
        "    review = movie_reviews.raw(fileid)\n",
        "    reviews_pos.append(review)\n",
        "\n",
        "reviews_neg = []\n",
        "for fileid in movie_reviews.fileids('neg'):\n",
        "    review = movie_reviews.raw(fileid)\n",
        "    reviews_neg.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiYAW2VgY6Gb"
      },
      "source": [
        "### Connect to the scoring API\n",
        "\n",
        "Fill in this function with code that connects to the Amazon Comprehend API, and uses it to score a single review:\n",
        "\n",
        "* [Documentation - Amazon Comprehend: Detect Sentiment](https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectSentiment.html)\n",
        "\n",
        "Your function must return either 'pos' or 'neg', so you'll need to make some decisions about how to map the results of the API call to one of these values. Amazon Comprehend can return \"NEUTRAL\" or \"MIXED\" for the Sentiment - if this happens, you will need to inspect the numeric values under the SentimentScore to see whether it leans toward positive or negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oyP_RMVY6Gc"
      },
      "outputs": [],
      "source": [
        "def score_review(review):\n",
        "    # COMPLETE THIS FUNCTION:\n",
        "    #\n",
        "    # You can find documentation about how Comprehend works in Python in the official docs\n",
        "    # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.detect_sentiment\n",
        "    #\n",
        "    # Your function will need to return 'pos' if a review is positive and\n",
        "    # 'neg' if the review is negative\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPi9HGn9Y6Gd"
      },
      "source": [
        "### Score each review\n",
        "\n",
        "Now, we can use the function you defined to score each of the reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNosJWBdY6Ge"
      },
      "outputs": [],
      "source": [
        "# Create 2 smaller subsets for testing\n",
        "subset_pos = reviews_pos[:10]\n",
        "subset_neg = reviews_neg[:10]\n",
        "\n",
        "results_pos = []\n",
        "# When comfortable with results switch `subset_pos` to reviews_pos`\n",
        "for review in subset_pos:\n",
        "    result = score_review(review)\n",
        "    results_pos.append(result)\n",
        "\n",
        "results_neg = []\n",
        "# When comfortable with results switch `subset_neg` to reviews_neg`\n",
        "for review in subset_neg:\n",
        "    result = score_review(review)\n",
        "    results_neg.append(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVbQ1W6BY6Ge"
      },
      "source": [
        "### Calculate accuracy\n",
        "\n",
        "For each of our known positive reviews, we can count the number which our function scored as 'pos', and use this to calculate the % accuracy. We repeaty this for negative reviews, and also for overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsMhxGbzY6Gf"
      },
      "outputs": [],
      "source": [
        "correct_pos = results_pos.count('pos')\n",
        "accuracy_pos = float(correct_pos) / len(results_pos)\n",
        "correct_neg = results_neg.count('neg')\n",
        "accuracy_neg = float(correct_neg) / len(results_neg)\n",
        "correct_all = correct_pos + correct_neg\n",
        "accuracy_all = float(correct_all) / (len(results_pos)+len(results_neg))\n",
        "\n",
        "print('Positive reviews: {}% correct'.format(accuracy_pos*100))\n",
        "print('Negative reviews: {}% correct'.format(accuracy_neg*100))\n",
        "print('Overall accuracy: {}% correct'.format(accuracy_all*100))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}